{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split-folders in /Users/rakshekarajakumar/anaconda3/envs/ee541_hw/lib/python3.11/site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "import torch, torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "!pip  install split-folders\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('Train')\n",
    "# os.makedirs('Test')\n",
    "# os.makedirs('Validate')\n",
    "os.makedirs('segregated_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir('S1_Raw_Photographs_Full_Study')\n",
    "\n",
    "initial_data_path=r'/Users/rakshekarajakumar/Documents/DEEP LEARNING/EE541_HW7/S1_Raw_Photographs_Full_Study'\n",
    "folder_path=r'/Users/rakshekarajakumar/Documents/DEEP LEARNING/EE541_HW7/segregated_images'\n",
    "\n",
    "random.shuffle(all_files)\n",
    "# for file in all_files:\n",
    "#     if file.startswith(\"Ethanol\"):\n",
    "#         label=file.split('_')[0]\n",
    "#         image_path= os.path.join(data_path, label)\n",
    "#         os.makedirs(image_path, exist_ok=True)\n",
    "#         shutil.copy(os.path.join(initial_data_path, file), image_path)\n",
    "    \n",
    "#     if file.startswith(\"Propanol\"):\n",
    "#         label=file.split('_')[0]\n",
    "#         image_path= os.path.join(data_path, label)\n",
    "#         os.makedirs(image_path, exist_ok=True)\n",
    "#         shutil.copy(os.path.join(initial_data_path, file), image_path)\n",
    "\n",
    "#     if file.startswith(\"Pentane\"):\n",
    "#         label=file.split('_')[0]\n",
    "#         image_path= os.path.join(data_path, label)\n",
    "#         os.makedirs(image_path, exist_ok=True)\n",
    "#         shutil.copy(os.path.join(initial_data_path, file), image_path)\n",
    "\n",
    "for file in all_files:\n",
    "    if file.endswith('.JPG'):\n",
    "        label= file.split('_')[0]\n",
    "        image_new_path= os.path.join(folder_path,label)\n",
    "        os.makedirs(image_new_path, exist_ok=True)\n",
    "        image_old_path= os.path.join(initial_data_path,file)\n",
    "        shutil.copy(image_old_path, image_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 3000 files [00:00, 5315.88 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio('segregated_images',seed=1337, output=\"TrainTestVal-Splitted\", ratio=(0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "# img = transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestVal= os.listdir('TrainTestVal-Splitted')\n",
    "# print(TrainTestVal)\n",
    "\n",
    "# print(os.listdir(os.path.join(os.path.join('TrainTestVal-Splitted', 'test'), 'ethanol')))\n",
    "\n",
    "# #accesssing all the images \n",
    "# for eachset in TrainTestVal:\n",
    "#     chemical_names= os.listdir(os.path.join('TrainTestVal-Splitted', eachset))\n",
    "#     # print(eachset,chemicalname)\n",
    "#     for chemical_name in chemical_names:\n",
    "#         chem_images= os.listdir(os.path.join(os.path.join('TrainTestVal-Splitted', eachset), chemical_name))\n",
    "#         for chem_image in chem_images:\n",
    "#             #print(eachset,chemical_name,chem_image)\n",
    "#             chem_image=transforms(chem_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='TrainTestVal-Splitted/train', transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(root='TrainTestVal-Splitted/test', transform=val_transforms)\n",
    "val_dataset = datasets.ImageFolder(root='TrainTestVal-Splitted/val', transform=val_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader= DataLoader(val_dataset,batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshekarajakumar/anaconda3/envs/ee541_hw/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/rakshekarajakumar/anaconda3/envs/ee541_hw/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "num_classes=3\n",
    "r_model = models.resnet34(pretrained=True)\n",
    "\n",
    "r_model.fc = nn.Linear(r_model.fc.in_features, num_classes)\n",
    "\n",
    "params = r_model.parameters()\n",
    "\n",
    "# for param in r_model.fc.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshekarajakumar/anaconda3/envs/ee541_hw/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/rakshekarajakumar/anaconda3/envs/ee541_hw/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained ResNet-34 model\n",
    "num_classes=3\n",
    "r_model = models.resnet34(pretrained=True)\n",
    "\n",
    "r_model.fc = nn.Linear(r_model.fc.in_features, num_classes)\n",
    "\n",
    "# for param in r_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in r_model.fc.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "\n",
    "for param in r_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in r_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer\n",
    "params_to_optimize = list({'params' : r_model.fc.parameters()})\n",
    "# optimizer = optim.SGD(params_to_optimize, lr=LEARNING_RATE, momentum=0.9)\n",
    "optimizer = optim.SGD([\n",
    "                {'params': r_model.fc.parameters()}\n",
    "            ], lr=1e-4, momentum=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, verbose=True)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_or_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "r_model = r_model.to(cpu_or_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/100\n",
      "    Training loss : 0.0643329918384552 | Training accuracy : 98.83333587646484\n",
      "    Validation loss : 0.0009710222366265953| Validation accuracy : 0.9833333492279053\n",
      "Epoch : 1/100\n",
      "    Training loss : 0.07109515368938446 | Training accuracy : 98.33333587646484\n",
      "    Validation loss : 0.0016050420235842466| Validation accuracy : 0.9666666388511658\n",
      "Epoch : 2/100\n",
      "    Training loss : 0.04839983582496643 | Training accuracy : 99.16666412353516\n",
      "    Validation loss : 0.0007674589869566262| Validation accuracy : 0.9833333492279053\n",
      "Epoch : 3/100\n",
      "    Training loss : 0.048701170831918716 | Training accuracy : 99.125\n",
      "    Validation loss : 0.0008434580522589386| Validation accuracy : 0.9866666793823242\n",
      "Epoch : 4/100\n",
      "    Training loss : 0.03597068414092064 | Training accuracy : 99.29166412353516\n",
      "    Validation loss : 0.000856335274875164| Validation accuracy : 0.9866666793823242\n",
      "Epoch : 5/100\n",
      "    Training loss : 0.03702739626169205 | Training accuracy : 99.625\n",
      "    Validation loss : 0.0010632060002535582| Validation accuracy : 0.9833333492279053\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs=100\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "train_loss=[]\n",
    "train_acc=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #train dataset\n",
    "    r_model.train()\n",
    "\n",
    "    training_loss=0\n",
    "    training_correct=0\n",
    "    for inputs_img,labels in train_dataloader:\n",
    "        inputs_img.to(cpu_or_gpu)\n",
    "        labels.to(cpu_or_gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs_lbl= r_model(inputs_img)\n",
    "        _,preds= torch.max(outputs_lbl,1)\n",
    "        loss= criterion(outputs_lbl,labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss+= loss\n",
    "        training_correct+= torch.sum(preds==labels)\n",
    "        \n",
    "    epoch_loss_training= training_loss/train_dataset.__len__() * 100\n",
    "    epoch_accuracy_training= training_correct/train_dataset.__len__() * 100\n",
    "\n",
    "    train_loss.append(epoch_loss_training)\n",
    "    train_acc.append(epoch_accuracy_training)\n",
    "\n",
    "    #val dataset\n",
    "    r_model.eval()\n",
    "    \n",
    "    validation_loss=0\n",
    "    validation_correct=0\n",
    "    for inputs,labels in val_dataloader:\n",
    "        inputs.to(cpu_or_gpu)\n",
    "        labels.to(cpu_or_gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs= r_model(inputs)\n",
    "        _,preds= torch.max(outputs,1)\n",
    "        loss= criterion(outputs,labels)\n",
    "\n",
    "        validation_loss+=loss\n",
    "        validation_correct+=torch.sum(preds==labels)\n",
    "\n",
    "    epoch_loss_validation= validation_loss/val_dataset.__len__()\n",
    "    epoch_accuracy_validation= validation_correct/val_dataset.__len__()\n",
    "\n",
    "    val_loss.append(epoch_loss_validation)\n",
    "    val_acc.append(epoch_accuracy_validation)\n",
    "\n",
    "    print(f\"Epoch : {epoch}/{epochs}\")\n",
    "    print(f\"    Training loss : {epoch_loss_training} | Training accuracy : {epoch_accuracy_training}\")\n",
    "    print(f\"    Validation loss : {epoch_loss_validation}| Validation accuracy : {epoch_accuracy_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/40\n",
      "    Training loss : 0.017271345481276512 | Training accuracy : 39.79166793823242\n",
      "    Validation loss : 0.017442990094423294| Validation accuracy : 46.0\n",
      "Epoch : 1/40\n",
      "    Training loss : 0.015585350804030895 | Training accuracy : 53.375\n",
      "    Validation loss : 0.01615646667778492| Validation accuracy : 56.33333206176758\n",
      "Epoch : 2/40\n",
      "    Training loss : 0.014313895255327225 | Training accuracy : 60.70833206176758\n",
      "    Validation loss : 0.015087286941707134| Validation accuracy : 66.33333587646484\n",
      "Epoch : 3/40\n",
      "    Training loss : 0.013219926506280899 | Training accuracy : 67.04166412353516\n",
      "    Validation loss : 0.014263882301747799| Validation accuracy : 70.66666412353516\n",
      "Epoch : 4/40\n",
      "    Training loss : 0.012305838987231255 | Training accuracy : 72.20833587646484\n",
      "    Validation loss : 0.013480971567332745| Validation accuracy : 74.33333587646484\n",
      "Epoch : 5/40\n",
      "    Training loss : 0.011676873080432415 | Training accuracy : 74.79166412353516\n",
      "    Validation loss : 0.012945312075316906| Validation accuracy : 76.0\n",
      "Epoch : 6/40\n",
      "    Training loss : 0.010926477611064911 | Training accuracy : 78.08332824707031\n",
      "    Validation loss : 0.012351065874099731| Validation accuracy : 77.0\n",
      "Epoch : 7/40\n",
      "    Training loss : 0.01054087933152914 | Training accuracy : 77.91666412353516\n",
      "    Validation loss : 0.011848353780806065| Validation accuracy : 79.66667175292969\n",
      "Epoch : 8/40\n",
      "    Training loss : 0.009598528034985065 | Training accuracy : 82.54167175292969\n",
      "    Validation loss : 0.010574345476925373| Validation accuracy : 83.0\n",
      "Epoch : 9/40\n",
      "    Training loss : 0.008659912273287773 | Training accuracy : 84.25\n",
      "    Validation loss : 0.009584393352270126| Validation accuracy : 85.66667175292969\n",
      "Epoch : 10/40\n",
      "    Training loss : 0.0076320902444422245 | Training accuracy : 87.04166412353516\n",
      "    Validation loss : 0.008825178258121014| Validation accuracy : 86.33333587646484\n",
      "Epoch : 11/40\n",
      "    Training loss : 0.007012262940406799 | Training accuracy : 88.20833587646484\n",
      "    Validation loss : 0.008157667703926563| Validation accuracy : 87.0\n",
      "Epoch : 12/40\n",
      "    Training loss : 0.006493037100881338 | Training accuracy : 88.83332824707031\n",
      "    Validation loss : 0.007625758647918701| Validation accuracy : 87.33333587646484\n",
      "Epoch : 13/40\n",
      "    Training loss : 0.005895824171602726 | Training accuracy : 89.54166412353516\n",
      "    Validation loss : 0.007159398403018713| Validation accuracy : 87.33333587646484\n",
      "Epoch : 14/40\n",
      "    Training loss : 0.005540462676435709 | Training accuracy : 91.0\n",
      "    Validation loss : 0.006709457840770483| Validation accuracy : 89.33332824707031\n",
      "Epoch : 15/40\n",
      "    Training loss : 0.005380269140005112 | Training accuracy : 89.79166412353516\n",
      "    Validation loss : 0.0067371162585914135| Validation accuracy : 87.0\n",
      "Epoch : 16/40\n",
      "    Training loss : 0.004884767346084118 | Training accuracy : 90.625\n",
      "    Validation loss : 0.0059870523400604725| Validation accuracy : 89.0\n",
      "Epoch : 17/40\n",
      "    Training loss : 0.004436733666807413 | Training accuracy : 92.16667175292969\n",
      "    Validation loss : 0.0057555609382689| Validation accuracy : 89.66666412353516\n",
      "Epoch : 18/40\n",
      "    Training loss : 0.004400651436299086 | Training accuracy : 91.58333587646484\n",
      "    Validation loss : 0.005560925230383873| Validation accuracy : 90.33332824707031\n",
      "Epoch : 19/40\n",
      "    Training loss : 0.0041834269650280476 | Training accuracy : 92.0\n",
      "    Validation loss : 0.005380970425903797| Validation accuracy : 89.66666412353516\n",
      "Epoch : 20/40\n",
      "    Training loss : 0.0039826943539083 | Training accuracy : 92.45832824707031\n",
      "    Validation loss : 0.005178559571504593| Validation accuracy : 91.33333587646484\n",
      "Epoch : 21/40\n",
      "    Training loss : 0.003861090401187539 | Training accuracy : 92.20832824707031\n",
      "    Validation loss : 0.004930652212351561| Validation accuracy : 91.33333587646484\n",
      "Epoch : 22/40\n",
      "    Training loss : 0.0037954405415803194 | Training accuracy : 91.625\n",
      "    Validation loss : 0.00484909163787961| Validation accuracy : 91.66667175292969\n",
      "Epoch : 23/40\n",
      "    Training loss : 0.0036592893302440643 | Training accuracy : 92.33333587646484\n",
      "    Validation loss : 0.0046110739931464195| Validation accuracy : 92.33333587646484\n",
      "Epoch : 24/40\n",
      "    Training loss : 0.0033949781209230423 | Training accuracy : 93.0\n",
      "    Validation loss : 0.0041824039071798325| Validation accuracy : 93.0\n",
      "Epoch : 25/40\n",
      "    Training loss : 0.003225871128961444 | Training accuracy : 93.375\n",
      "    Validation loss : 0.004109164234250784| Validation accuracy : 93.0\n",
      "Epoch : 26/40\n",
      "    Training loss : 0.003256982658058405 | Training accuracy : 93.25\n",
      "    Validation loss : 0.0041664461605250835| Validation accuracy : 92.66666412353516\n",
      "Epoch : 27/40\n",
      "    Training loss : 0.0030714080203324556 | Training accuracy : 93.41666412353516\n",
      "    Validation loss : 0.0040167029947042465| Validation accuracy : 92.66666412353516\n",
      "Epoch : 28/40\n",
      "    Training loss : 0.0031697216909378767 | Training accuracy : 92.625\n",
      "    Validation loss : 0.0038405617233365774| Validation accuracy : 93.0\n",
      "Epoch : 29/40\n",
      "    Training loss : 0.002997693605720997 | Training accuracy : 93.125\n",
      "    Validation loss : 0.003774706507101655| Validation accuracy : 93.0\n",
      "Epoch : 30/40\n",
      "    Training loss : 0.0029622921720147133 | Training accuracy : 93.25\n",
      "    Validation loss : 0.0036216843873262405| Validation accuracy : 93.0\n",
      "Epoch : 31/40\n",
      "    Training loss : 0.0029061578679829836 | Training accuracy : 93.41666412353516\n",
      "    Validation loss : 0.0036963229067623615| Validation accuracy : 93.33333587646484\n",
      "Epoch : 32/40\n",
      "    Training loss : 0.002766138408333063 | Training accuracy : 94.04167175292969\n",
      "    Validation loss : 0.0036266748793423176| Validation accuracy : 93.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs=40\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "train_loss=[]\n",
    "train_acc=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #----freezing and unfreezing layers----#\n",
    "    if epoch == 8:\n",
    "        for param in r_model.layer4.parameters():\n",
    "            param.requires_grad = True  \n",
    "    optimizer = optim.SGD([\n",
    "                    {'params': r_model.fc.parameters()}, \n",
    "                    {'params': r_model.layer4.parameters(), 'lr': 1e-4}\n",
    "                ], lr=1e-4, momentum=0.9)\n",
    "            \n",
    "    if epoch == 16:\n",
    "        for param in r_model.layer3.parameters():\n",
    "            param.requires_grad = True \n",
    "        params_to_optimize.append({'params': r_model.layer3.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4})\n",
    "        optimizer = optim.SGD([\n",
    "                        {'params': r_model.fc.parameters()}, \n",
    "                        {'params': r_model.layer4.parameters(), 'lr': 1e-4, 'weight_decay' : 1e-4},\n",
    "                        {'params': r_model.layer3.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4}\n",
    "                    ], lr=1e-4, momentum=0.9)\n",
    "            \n",
    "    if epoch == 24:\n",
    "        for param in r_model.layer2.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer = optim.SGD([\n",
    "                        {'params': r_model.fc.parameters()}, \n",
    "                        {'params': r_model.layer4.parameters(), 'lr': 1e-4, 'weight_decay' : 1e-4},\n",
    "                        {'params': r_model.layer3.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4},\n",
    "                        {'params': r_model.layer2.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4}\n",
    "                    ], lr=1e-4, momentum=0.9)\n",
    "            \n",
    "    if epoch == 50:\n",
    "        for param in r_model.layer1.parameters():\n",
    "            param.requires_grad = True \n",
    "        params_to_optimize.append({'params': r_model.layer1.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4})\n",
    "        optimizer = optim.SGD([\n",
    "                        {'params': r_model.fc.parameters()}, \n",
    "                        {'params': r_model.layer4.parameters(), 'lr': 1e-4, 'weight_decay' : 1e-4},\n",
    "                        {'params': r_model.layer3.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4},\n",
    "                        {'params': r_model.layer2.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4}, \n",
    "                        {'params': r_model.layer1.parameters(), 'lr': 0.0001, 'weight_decay': 1e-4}\n",
    "                    ], lr=1e-4, momentum=0.9)\n",
    "    \n",
    "    \n",
    "    #----freezing and unfreezing layers----#\n",
    "\n",
    "    #train dataset\n",
    "    r_model.train()\n",
    "\n",
    "    training_loss=0\n",
    "    training_correct=0\n",
    "    for inputs_img,labels in train_dataloader:\n",
    "        inputs_img.to(cpu_or_gpu)\n",
    "        labels.to(cpu_or_gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs_lbl= r_model(inputs_img)\n",
    "        _,preds= torch.max(outputs_lbl,1)\n",
    "        loss= criterion(outputs_lbl,labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss+= loss\n",
    "        training_correct+= torch.sum(preds==labels)\n",
    "        \n",
    "    epoch_loss_training= training_loss/train_dataset.__len__()\n",
    "    epoch_accuracy_training= training_correct/train_dataset.__len__() * 100\n",
    "\n",
    "    train_loss.append(epoch_loss_training)\n",
    "    train_acc.append(epoch_accuracy_training)\n",
    "\n",
    "    #val dataset\n",
    "    r_model.eval()\n",
    "    \n",
    "    validation_loss=0\n",
    "    validation_correct=0\n",
    "    for inputs,labels in val_dataloader:\n",
    "        inputs.to(cpu_or_gpu)\n",
    "        labels.to(cpu_or_gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs= r_model(inputs)\n",
    "        _,preds= torch.max(outputs,1)\n",
    "        loss= criterion(outputs,labels)\n",
    "\n",
    "        validation_loss+=loss\n",
    "        validation_correct+=torch.sum(preds==labels)\n",
    "\n",
    "    epoch_loss_validation= validation_loss/val_dataset.__len__()\n",
    "    epoch_accuracy_validation= validation_correct/val_dataset.__len__() * 100\n",
    "\n",
    "    val_loss.append(epoch_loss_validation)\n",
    "    val_acc.append(epoch_accuracy_validation)\n",
    "\n",
    "    print(f\"Epoch : {epoch}/{epochs}\")\n",
    "    print(f\"    Training loss : {epoch_loss_training} | Training accuracy : {epoch_accuracy_training}\")\n",
    "    print(f\"    Validation loss : {epoch_loss_validation}| Validation accuracy : {epoch_accuracy_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plottings(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    unfreeze = [25, 40, 55, 70]\n",
    "    # for accuracy\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(train_acc, color='red', linestyle='o', label='train accuracy')\n",
    "    plt.plot(valid_acc, color='green', linestyle='-', label='validataion accuracy')\n",
    "    for point in unfreeze:\n",
    "        plt.axvline(x=point, color='blue', linestyle='-o-', label='Unfreezed Layers at')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    plt.savefig('accuracy.png')\n",
    "    \n",
    "    #for loss\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='orange', linestyle='-', label='train loss')\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', label='validataion loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rakshekarajakumar/Documents/DEEP LEARNING/EE541_HW7/homework7.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rakshekarajakumar/Documents/DEEP%20LEARNING/EE541_HW7/homework7.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m save_plots(train_acc\u001b[39m=\u001b[39mtrain_acc, valid_acc\u001b[39m=\u001b[39mval_acc, train_loss\u001b[39m=\u001b[39mtrain_loss, valid_loss\u001b[39m=\u001b[39mval_loss)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
     ]
    }
   ],
   "source": [
    "plottings(train_acc=train_acc, valid_acc=val_acc, train_loss=train_loss, valid_loss=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "all_labels = []\n",
    "probabilities = []\n",
    "#calculating visualizations\n",
    "r_model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = r_model(inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        probabilities.extend(probs.numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(preds.numpy())\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "probabilities = np.array(probabilities)\n",
    "true_labels = np.array(true_labels)\n",
    "print(probabilities.shape, true_labels.shape)\n",
    "true_labels_one_hot = np.eye(3)[true_labels]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for class_index in range(3):\n",
    "    precision, recall, _ = precision_recall_curve(\n",
    "        true_labels_one_hot[:, class_index],\n",
    "        probabilities[:, class_index]\n",
    "    )\n",
    "    plt.plot(recall, precision, label=f'Class {class_index}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (ResNet34) ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_model)\n",
    "def hook_visualization(module, input, output):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(output.size(1)):\n",
    "        plt.subplot(8, 8, i + 1)\n",
    "        plt.imshow(output[0, i].detach().cpu().numpy(), cmap=\"viridis\") \n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "visual_layer = r_model.layer2[0].conv1\n",
    "hook = visual_layer.register_forward_hook(hook_visualization)\n",
    "image_path = 'data\\Test\\Ethanol\\Ethanol_Full_0002.JPG'\n",
    "image = Image.open(image_path)\n",
    "input_image = val_transforms(image).unsqueeze(0)\n",
    "xyz= r_model(input_image)\n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 10\n",
    "\n",
    "test_loss=[]\n",
    "test_acc=[]\n",
    "test_correct=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    r_model.eval()\n",
    "    \n",
    "    epoch_loss_test=0\n",
    "    epoch_acc_test=0\n",
    "\n",
    "    for inputs,labels in test_dataloader:\n",
    "        inputs.to(cpu_or_gpu)\n",
    "        labels.to(cpu_or_gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs= r_model(inputs)\n",
    "        _,preds= torch.max(outputs,1)\n",
    "        loss= criterion(outputs,labels)\n",
    "\n",
    "        test_loss+=loss\n",
    "        test_correct+=torch.sum(preds==labels)\n",
    "\n",
    "    epoch_loss_test= test_loss/test_dataset.__len__()\n",
    "    epoch_accuracy_test= test_correct/test_dataset.__len__() * 100\n",
    "\n",
    "    test_loss.append(epoch_loss_test)\n",
    "    test_acc.append(epoch_accuracy_test)\n",
    "    \n",
    "    print(f\"epoch : {epoch}/{epochs}\")\n",
    "    print(f\"test loss : {test_loss} | test accuracy : {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee541_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
